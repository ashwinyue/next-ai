package service

import (
	"context"
	"fmt"
	"log"

	"github.com/ashwinyue/next-ai/internal/config"
	"github.com/ashwinyue/next-ai/internal/model"
	"github.com/ashwinyue/next-ai/internal/repository"
	"github.com/cloudwego/eino-ext/components/tool/duckduckgo/v2"
	httptool "github.com/cloudwego/eino-ext/components/tool/httprequest"
	sequencethinking "github.com/cloudwego/eino-ext/components/tool/sequentialthinking"
	wikipediatool "github.com/cloudwego/eino-ext/components/tool/wikipedia"
	"github.com/cloudwego/eino/components/tool"
	"github.com/cloudwego/eino/components/tool/utils"
	"github.com/cloudwego/eino/schema"
)

// PlanStep è®¡åˆ’æ­¥éª¤
type PlanStep struct {
	ID          string `json:"id" jsonschema_description:"æ­¥éª¤ID"`
	Description string `json:"description" jsonschema_description:"æ­¥éª¤æè¿°"`
	Status      string `json:"status" jsonschema_description:"çŠ¶æ€: pending, in_progress, completed"`
}

// TodoWriteInput todo_write è¾“å…¥å‚æ•°
type TodoWriteInput struct {
	Task  string     `json:"task" jsonschema_description:"ä»»åŠ¡æè¿°"`
	Steps []PlanStep `json:"steps" jsonschema_description:"ä»»åŠ¡æ­¥éª¤åˆ—è¡¨"`
}

// KnowledgeSearchInput çŸ¥è¯†åº“æœç´¢è¾“å…¥
type KnowledgeSearchInput struct {
	Query string `json:"query" jsonschema_description:"The search query" jsonschema_required:"true"`
	TopK  int    `json:"top_k" jsonschema_description:"Number of results (default 10)"`
}

// KnowledgeSearchOutput çŸ¥è¯†åº“æœç´¢è¾“å‡º
type KnowledgeSearchOutput struct {
	Query   string                   `json:"query"`
	Total   int                      `json:"total"`
	Results []map[string]interface{} `json:"results"`
}

// DocumentInfoInput æ–‡æ¡£ä¿¡æ¯è¾“å…¥
type DocumentInfoInput struct {
	DocumentIDs []string `json:"document_ids" jsonschema_description:"æ–‡æ¡£ ID åˆ—è¡¨ï¼Œæœ€å¤š 10 ä¸ª" jsonschema_required:"true"`
}

// DocumentInfoOutput æ–‡æ¡£ä¿¡æ¯è¾“å‡º
type DocumentInfoOutput struct {
	Count     int                      `json:"count"`
	Documents []map[string]interface{} `json:"documents"`
}

// ListChunksInput åˆ—å‡ºåˆ†å—è¾“å…¥
type ListChunksInput struct {
	DocumentID string `json:"document_id" jsonschema_description:"æ–‡æ¡£ ID" jsonschema_required:"true"`
}

// ChunkItem åˆ†å—é¡¹
type ChunkItem struct {
	ID         string `json:"id"`
	ChunkIndex int    `json:"chunk_index"`
	Content    string `json:"content"`
}

// ListChunksOutput åˆ—å‡ºåˆ†å—è¾“å‡º
type ListChunksOutput struct {
	DocumentID string      `json:"document_id"`
	Title      string      `json:"title"`
	Total      int         `json:"total"`
	Chunks     []ChunkItem `json:"chunks"`
}

// GrepChunksInput åˆ†å—æœç´¢è¾“å…¥
type GrepChunksInput struct {
	Pattern    string `json:"pattern" jsonschema_description:"æœç´¢æ¨¡å¼ï¼ˆæ–‡æœ¬ï¼‰" jsonschema_required:"true"`
	DocumentID string `json:"document_id" jsonschema_description:"å¯é€‰ï¼šé™åˆ¶åœ¨ç‰¹å®šæ–‡æ¡£ä¸­æœç´¢"`
}

// GrepChunkItem æœç´¢ç»“æœé¡¹
type GrepChunkItem struct {
	ID         string `json:"id"`
	DocumentID string `json:"document_id"`
	ChunkIndex int    `json:"chunk_index"`
	Content    string `json:"content"`
}

// GrepChunksOutput åˆ†å—æœç´¢è¾“å‡º
type GrepChunksOutput struct {
	Pattern string          `json:"pattern"`
	Count   int             `json:"count"`
	Matches []GrepChunkItem `json:"matches"`
}

// stubTool å ä½å·¥å…·
type stubTool struct {
	name string
}

func (t *stubTool) Info(ctx context.Context) (*schema.ToolInfo, error) {
	return &schema.ToolInfo{
		Name: t.name,
		Desc: t.name + " (unavailable)",
		ParamsOneOf: schema.NewParamsOneOfByParams(map[string]*schema.ParameterInfo{
			"query": {
				Type:     schema.String,
				Desc:     "The query string",
				Required: true,
			},
		}),
	}, nil
}

func (t *stubTool) InvokableRun(ctx context.Context, argumentsInJSON string, opts ...tool.Option) (string, error) {
	return fmt.Sprintf(`{"error":"%s is not available"}`, t.name), nil
}

// newWebSearchTool åˆ›å»ºç½‘ç»œæœç´¢å·¥å…·
func newWebSearchTool(ctx context.Context) tool.InvokableTool {
	searchTool, err := duckduckgo.NewTextSearchTool(ctx, &duckduckgo.Config{
		ToolName:   "web_search",
		ToolDesc:   "Search the web for current information using DuckDuckGo. Use this when you need up-to-date information or the knowledge base doesn't have the answer.",
		MaxResults: 10,
	})
	if err != nil {
		log.Printf("Warning: failed to create web search tool: %v", err)
		return &stubTool{name: "web_search"}
	}

	return searchTool
}

// newTools åˆå§‹åŒ–æ‰€æœ‰å·¥å…·
func newTools(ctx context.Context, cfg *config.Config, retriever interface{}, repo *repository.Repositories) []tool.BaseTool {
	tools := []tool.BaseTool{}

	// æ·»åŠ ç½‘ç»œæœç´¢å·¥å…· (eino-ext duckduckgo)
	tools = append(tools, newWebSearchTool(ctx))

	// æ·»åŠ  HTTP è¯·æ±‚å·¥å…· (eino-ext httprequest)
	httpTools, err := httptool.NewToolKit(ctx, &httptool.Config{})
	if err != nil {
		log.Printf("Warning: failed to create http tools: %v", err)
	} else {
		tools = append(tools, httpTools...)
	}

	// æ·»åŠ  Wikipedia æœç´¢å·¥å…· (eino-ext wikipedia)
	wikiTool, err := wikipediatool.NewTool(ctx, &wikipediatool.Config{
		Language: "zh", // ä¸­æ–‡ Wikipedia
		TopK:     3,
	})
	if err != nil {
		log.Printf("Warning: failed to create wikipedia tool: %v", err)
	} else {
		tools = append(tools, wikiTool)
	}

	// æ·»åŠ é¡ºåºæ€è€ƒå·¥å…· (eino-ext sequentialthinking)
	thinkTool, err := sequencethinking.NewTool()
	if err != nil {
		log.Printf("Warning: failed to create sequentialthinking tool: %v", err)
	} else {
		tools = append(tools, thinkTool)
	}

	// æ·»åŠ  todo_write å·¥å…·
	tools = append(tools, newTodoWriteTool())

	// æ·»åŠ çŸ¥è¯†åº“æœç´¢å·¥å…·
	if retriever != nil {
		tools = append(tools, newKnowledgeSearchTool(retriever))
	}

	// æ·»åŠ æ–‡æ¡£ç›¸å…³å·¥å…·
	if repo != nil {
		tools = append(tools, newDocumentInfoTool(repo))
		tools = append(tools, newListChunksTool(repo))
		tools = append(tools, newGrepChunksTool(repo))
	}

	return tools
}

// newTodoWriteTool åˆ›å»ºä»»åŠ¡è®¡åˆ’å·¥å…·
func newTodoWriteTool() tool.InvokableTool {
	t, err := utils.InferTool(
		"todo_write",
		`åˆ›å»ºå’Œç®¡ç†ç»“æ„åŒ–çš„æ£€ç´¢ä»»åŠ¡åˆ—è¡¨ã€‚ç”¨äºè·Ÿè¸ªå¤æ‚ä»»åŠ¡çš„è¿›åº¦ã€‚

**ä½¿ç”¨åœºæ™¯**ï¼š
- å¤æ‚å¤šæ­¥éª¤ä»»åŠ¡ï¼ˆ3ä¸ªæˆ–ä»¥ä¸Šæ­¥éª¤ï¼‰
- éœ€è¦ä»”ç»†è§„åˆ’çš„æ“ä½œ
- ç”¨æˆ·æ˜ç¡®è¯·æ±‚åˆ›å»ºä»»åŠ¡åˆ—è¡¨

**ä»»åŠ¡çŠ¶æ€**ï¼š
- pending: æœªå¼€å§‹
- in_progress: è¿›è¡Œä¸­ï¼ˆåŒæ—¶åªèƒ½æœ‰ä¸€ä¸ªï¼‰
- completed: å·²å®Œæˆ

**é‡è¦**ï¼š
- ä»…åŒ…å«æ£€ç´¢/ç ”ç©¶ä»»åŠ¡ï¼Œä¸åŒ…å«æ€»ç»“ä»»åŠ¡
- å®Œæˆæ‰€æœ‰æ£€ç´¢ä»»åŠ¡åï¼Œä½¿ç”¨ thinking å·¥å…·è¿›è¡Œæ€»ç»“`,
		func(ctx context.Context, input *TodoWriteInput) (string, error) {
			if input.Task == "" {
				input.Task = "æœªæä¾›ä»»åŠ¡æè¿°"
			}
			return generateTodoOutput(input.Task, input.Steps), nil
		},
	)
	if err != nil {
		log.Printf("Warning: failed to create todo_write tool: %v", err)
		return nil
	}
	return t
}

// newKnowledgeSearchTool åˆ›å»ºçŸ¥è¯†åº“æœç´¢å·¥å…·
func newKnowledgeSearchTool(r interface{}) tool.InvokableTool {
	t, err := utils.InferTool(
		"knowledge_search",
		"Searches the knowledge base for relevant information using semantic and keyword search.",
		func(ctx context.Context, input *KnowledgeSearchInput) (*KnowledgeSearchOutput, error) {
			if input.Query == "" {
				return nil, fmt.Errorf("query is required")
			}
			if input.TopK <= 0 {
				input.TopK = 10
			}

			// ä½¿ç”¨ retriever.Retrieve æ¥å£
			docs, err := retrieveInterface(r, ctx, input.Query, input.TopK)
			if err != nil {
				return nil, fmt.Errorf("retriever failed: %w", err)
			}

			results := make([]map[string]interface{}, 0, len(docs))
			for _, doc := range docs {
				result := map[string]interface{}{
					"content": doc.Content,
					"score":   doc.Score(),
				}
				if doc.MetaData != nil {
					if title, ok := doc.MetaData["title"].(string); ok {
						result["title"] = title
					}
				}
				results = append(results, result)
			}

			return &KnowledgeSearchOutput{
				Query:   input.Query,
				Total:   len(results),
				Results: results,
			}, nil
		},
	)
	if err != nil {
		log.Printf("Warning: failed to create knowledge_search tool: %v", err)
		return nil
	}
	return t
}

// newDocumentInfoTool åˆ›å»ºæ–‡æ¡£ä¿¡æ¯å·¥å…·
func newDocumentInfoTool(repo *repository.Repositories) tool.InvokableTool {
	t, err := utils.InferTool(
		"get_document_info",
		"è·å–æ–‡æ¡£çš„è¯¦ç»†å…ƒæ•°æ®ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€æ–‡ä»¶åã€å¤§å°ã€åˆ†å—æ•°é‡ç­‰ã€‚ç”¨äºæŸ¥è¯¢æ–‡æ¡£åŸºæœ¬ä¿¡æ¯å’Œå¤„ç†çŠ¶æ€ã€‚",
		func(ctx context.Context, input *DocumentInfoInput) (*DocumentInfoOutput, error) {
			if len(input.DocumentIDs) == 0 {
				return nil, fmt.Errorf("document_ids is required")
			}
			if len(input.DocumentIDs) > 10 {
				return nil, fmt.Errorf("maximum 10 document IDs allowed")
			}

			results := make([]map[string]interface{}, 0)
			for _, docID := range input.DocumentIDs {
				doc, err := repo.Knowledge.GetDocumentByID(docID)
				if err != nil {
					continue
				}
				chunks, _ := repo.Knowledge.GetChunksByDocumentID(docID)

				results = append(results, map[string]interface{}{
					"id":           doc.ID,
					"title":        doc.Title,
					"file_name":    doc.FileName,
					"file_size":    doc.FileSize,
					"content_type": doc.ContentType,
					"status":       doc.Status,
					"chunk_count":  len(chunks),
					"created_at":   doc.CreatedAt,
				})
			}

			return &DocumentInfoOutput{
				Count:     len(results),
				Documents: results,
			}, nil
		},
	)
	if err != nil {
		log.Printf("Warning: failed to create get_document_info tool: %v", err)
		return nil
	}
	return t
}

// newListChunksTool åˆ›å»ºåˆ—å‡ºåˆ†å—å·¥å…·
func newListChunksTool(repo *repository.Repositories) tool.InvokableTool {
	t, err := utils.InferTool(
		"list_chunks",
		"è·å–æŒ‡å®šæ–‡æ¡£çš„æ‰€æœ‰åˆ†å—å†…å®¹ã€‚ç”¨äºæŸ¥çœ‹æ–‡æ¡£çš„å®Œæ•´åˆ†å—åˆ—è¡¨ã€‚",
		func(ctx context.Context, input *ListChunksInput) (*ListChunksOutput, error) {
			if input.DocumentID == "" {
				return nil, fmt.Errorf("document_id is required")
			}

			doc, err := repo.Knowledge.GetDocumentByID(input.DocumentID)
			if err != nil {
				return nil, fmt.Errorf("document not found: %w", err)
			}

			chunks, err := repo.Knowledge.GetChunksByDocumentID(input.DocumentID)
			if err != nil {
				return nil, fmt.Errorf("failed to get chunks: %w", err)
			}

			chunkList := make([]ChunkItem, 0, len(chunks))
			for _, c := range chunks {
				chunkList = append(chunkList, ChunkItem{
					ID:         c.ID,
					ChunkIndex: c.ChunkIndex,
					Content:    c.Content,
				})
			}

			return &ListChunksOutput{
				DocumentID: doc.ID,
				Title:      doc.Title,
				Total:      len(chunks),
				Chunks:     chunkList,
			}, nil
		},
	)
	if err != nil {
		log.Printf("Warning: failed to create list_chunks tool: %v", err)
		return nil
	}
	return t
}

// newGrepChunksTool åˆ›å»ºåˆ†å—æœç´¢å·¥å…·
func newGrepChunksTool(repo *repository.Repositories) tool.InvokableTool {
	t, err := utils.InferTool(
		"grep_chunks",
		"åœ¨æ–‡æ¡£åˆ†å—ä¸­æœç´¢åŒ…å«ç‰¹å®šæ–‡æœ¬çš„å†…å®¹ã€‚æ”¯æŒç²¾ç¡®æ–‡æœ¬åŒ¹é…ã€‚",
		func(ctx context.Context, input *GrepChunksInput) (*GrepChunksOutput, error) {
			if input.Pattern == "" {
				return nil, fmt.Errorf("pattern is required")
			}

			var chunks []*model.DocumentChunk
			var err error

			if input.DocumentID != "" {
				// æœç´¢ç‰¹å®šæ–‡æ¡£çš„åˆ†å—
				chunks, err = repo.Knowledge.GetChunksByDocumentID(input.DocumentID)
				if err != nil {
					return nil, fmt.Errorf("failed to get chunks: %w", err)
				}
			}

			// è¿‡æ»¤åŒ…å«åŒ¹é…å†…å®¹çš„åˆ†å—
			matches := make([]GrepChunkItem, 0)
			for _, c := range chunks {
				if containsIgnoreCase(c.Content, input.Pattern) {
					matches = append(matches, GrepChunkItem{
						ID:         c.ID,
						DocumentID: c.DocumentID,
						ChunkIndex: c.ChunkIndex,
						Content:    c.Content,
					})
				}
			}

			return &GrepChunksOutput{
				Pattern: input.Pattern,
				Count:   len(matches),
				Matches: matches,
			}, nil
		},
	)
	if err != nil {
		log.Printf("Warning: failed to create grep_chunks tool: %v", err)
		return nil
	}
	return t
}

// GetToolsByName æ ¹æ®åç§°è·å–å·¥å…·
func GetToolsByName(ctx context.Context, names []string, allTools []tool.BaseTool) ([]tool.BaseTool, error) {
	if len(names) == 0 {
		return allTools, nil
	}

	toolMap := make(map[string]tool.BaseTool)
	for _, t := range allTools {
		info, err := t.Info(ctx)
		if err != nil {
			continue
		}
		toolMap[info.Name] = t
	}

	result := make([]tool.BaseTool, 0, len(names))
	for _, name := range names {
		t, ok := toolMap[name]
		if !ok {
			return nil, fmt.Errorf("tool not found: %s", name)
		}
		result = append(result, t)
	}

	return result, nil
}

// ListToolNames åˆ—å‡ºæ‰€æœ‰å·¥å…·åç§°
func ListToolNames(ctx context.Context, allTools []tool.BaseTool) []string {
	names := make([]string, 0, len(allTools))
	for _, t := range allTools {
		info, err := t.Info(ctx)
		if err != nil {
			continue
		}
		names = append(names, info.Name)
	}
	return names
}

// generateTodoOutput ç”Ÿæˆ todo è¾“å‡º
func generateTodoOutput(task string, steps []PlanStep) string {
	output := "## è®¡åˆ’å·²åˆ›å»º\n\n"
	output += fmt.Sprintf("**ä»»åŠ¡**: %s\n\n", task)

	if len(steps) == 0 {
		output += "æ³¨æ„ï¼šæœªæä¾›å…·ä½“æ­¥éª¤ã€‚å»ºè®®åˆ›å»º3-7ä¸ªæ£€ç´¢ä»»åŠ¡ã€‚\n\n"
		output += "å»ºè®®çš„æ£€ç´¢æµç¨‹ï¼š\n"
		output += "1. ä½¿ç”¨ grep_chunks æœç´¢å…³é”®è¯å®šä½ç›¸å…³æ–‡æ¡£\n"
		output += "2. ä½¿ç”¨ knowledge_search è¿›è¡Œè¯­ä¹‰æœç´¢è·å–ç›¸å…³å†…å®¹\n"
		output += "3. ä½¿ç”¨ list_chunks è·å–å…³é”®æ–‡æ¡£çš„å®Œæ•´å†…å®¹\n"
		output += "4. ä½¿ç”¨ web_search è·å–è¡¥å……ä¿¡æ¯ï¼ˆå¦‚éœ€è¦ï¼‰\n"
		return output
	}

	// ç»Ÿè®¡ä»»åŠ¡çŠ¶æ€
	pendingCount := 0
	inProgressCount := 0
	completedCount := 0
	for _, step := range steps {
		switch step.Status {
		case "pending":
			pendingCount++
		case "in_progress":
			inProgressCount++
		case "completed":
			completedCount++
		}
	}
	totalCount := len(steps)
	remainingCount := pendingCount + inProgressCount

	output += "**ä»»åŠ¡æ­¥éª¤**:\n\n"
	for i, step := range steps {
		output += formatTodoStep(i+1, step)
	}

	// æ·»åŠ è¿›åº¦æ±‡æ€»
	output += "\n## ä»»åŠ¡è¿›åº¦\n"
	output += fmt.Sprintf("æ€»è®¡: %d ä¸ªä»»åŠ¡ | ", totalCount)
	output += fmt.Sprintf("âœ… å·²å®Œæˆ: %d | ", completedCount)
	output += fmt.Sprintf("ğŸ”„ è¿›è¡Œä¸­: %d | ", inProgressCount)
	output += fmt.Sprintf("â³ å¾…å¤„ç†: %d\n\n", pendingCount)

	// æ·»åŠ æé†’
	output += "## âš ï¸ é‡è¦æé†’\n"
	if remainingCount > 0 {
		output += fmt.Sprintf("**è¿˜æœ‰ %d ä¸ªä»»åŠ¡æœªå®Œæˆï¼**\n\n", remainingCount)
		output += "**å¿…é¡»å®Œæˆæ‰€æœ‰ä»»åŠ¡åæ‰èƒ½æ€»ç»“æˆ–å¾—å‡ºç»“è®ºã€‚**\n\n"
		output += "ä¸‹ä¸€æ­¥æ“ä½œï¼š\n"
		if inProgressCount > 0 {
			output += "- ç»§ç»­å®Œæˆå½“å‰è¿›è¡Œä¸­çš„ä»»åŠ¡\n"
		}
		if pendingCount > 0 {
			output += fmt.Sprintf("- å¼€å§‹å¤„ç† %d ä¸ªå¾…å¤„ç†ä»»åŠ¡\n", pendingCount)
		}
		output += "- å®Œæˆæ¯ä¸ªä»»åŠ¡åï¼Œæ›´æ–° todo_write æ ‡è®°ä¸º completed\n"
		output += "- æ‰€æœ‰ä»»åŠ¡å®Œæˆåï¼Œä½¿ç”¨ thinking å·¥å…·ç”Ÿæˆæœ€ç»ˆæ€»ç»“\n"
	} else {
		output += "âœ… **æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼**\n\n"
		output += "ç°åœ¨å¯ä»¥ï¼š\n"
		output += "- ç»¼åˆæ‰€æœ‰ä»»åŠ¡çš„å‘ç°\n"
		output += "- ä½¿ç”¨ thinking å·¥å…·ç”Ÿæˆå®Œæ•´çš„æœ€ç»ˆç­”æ¡ˆ\n"
	}

	return output
}

// formatTodoStep æ ¼å¼åŒ–å•ä¸ªä»»åŠ¡æ­¥éª¤
func formatTodoStep(index int, step PlanStep) string {
	statusEmoji := map[string]string{
		"pending":     "â³",
		"in_progress": "ğŸ”„",
		"completed":   "âœ…",
	}

	emoji, ok := statusEmoji[step.Status]
	if !ok {
		emoji = "â³"
	}

	return fmt.Sprintf("%d. %s [%s] %s\n", index, emoji, step.Status, step.Description)
}

// retrieveInterface è°ƒç”¨ retriever çš„æ¥å£
func retrieveInterface(r interface{}, ctx context.Context, query string, topK int) ([]*schema.Document, error) {
	// è¿™é‡Œä½¿ç”¨ç±»å‹æ–­è¨€æ¥å¤„ç†ä¸åŒçš„ retriever ç±»å‹
	// å®é™…å®ç°å–å†³äº retriever çš„å…·ä½“ç±»å‹
	type retrieverInterface interface {
		Retrieve(ctx context.Context, query string, opts ...interface{}) ([]*schema.Document, error)
	}

	if retriever, ok := r.(retrieverInterface); ok {
		return retriever.Retrieve(ctx, query)
	}

	return nil, fmt.Errorf("unsupported retriever type")
}
