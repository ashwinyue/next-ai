package service

import (
	"context"
	"encoding/json"
	"fmt"
	"log"
	"time"

	"github.com/ashwinyue/next-ai/internal/service/file"
	"github.com/ashwinyue/next-ai/internal/config"
	"github.com/ashwinyue/next-ai/internal/model"
	"github.com/ashwinyue/next-ai/internal/repository"
	"github.com/ashwinyue/next-ai/internal/service/agent"
	"github.com/ashwinyue/next-ai/internal/service/auth"
	"github.com/ashwinyue/next-ai/internal/service/chat"
	"github.com/ashwinyue/next-ai/internal/service/callback"
	"github.com/ashwinyue/next-ai/internal/service/chunk"
	"github.com/ashwinyue/next-ai/internal/service/dataset"
	"github.com/ashwinyue/next-ai/internal/service/event"
	"github.com/ashwinyue/next-ai/internal/service/evaluation"
	"github.com/ashwinyue/next-ai/internal/service/faq"
	"github.com/ashwinyue/next-ai/internal/service/initialization"
	svcModel "github.com/ashwinyue/next-ai/internal/service/model"
	"github.com/ashwinyue/next-ai/internal/service/knowledge"
	svcmcp "github.com/ashwinyue/next-ai/internal/service/mcp"
	"github.com/ashwinyue/next-ai/internal/service/query"
	"github.com/ashwinyue/next-ai/internal/service/rewrite"
	"github.com/ashwinyue/next-ai/internal/service/session"
	svctag "github.com/ashwinyue/next-ai/internal/service/tag"
	svctenant "github.com/ashwinyue/next-ai/internal/service/tenant"
	"github.com/ashwinyue/next-ai/internal/service/tool"
	"github.com/ashwinyue/next-ai/internal/service/types"
	"github.com/cloudwego/eino-ext/components/embedding/dashscope"
	"github.com/cloudwego/eino-ext/components/model/openai"
	"github.com/cloudwego/eino-ext/components/retriever/es8"
	"github.com/cloudwego/eino-ext/components/retriever/es8/search_mode"
	duckduckgov2 "github.com/cloudwego/eino-ext/components/tool/duckduckgo/v2"
	httptool "github.com/cloudwego/eino-ext/components/tool/httprequest"
	sequencethinking "github.com/cloudwego/eino-ext/components/tool/sequentialthinking"
	wikipediatool "github.com/cloudwego/eino-ext/components/tool/wikipedia"
	"github.com/cloudwego/eino/components/embedding"
	ecomodel "github.com/cloudwego/eino/components/model"
	"github.com/cloudwego/eino/components/retriever"
	einotool "github.com/cloudwego/eino/components/tool"
	"github.com/cloudwego/eino/components/tool/utils"
	"github.com/cloudwego/eino/schema"
	"github.com/elastic/go-elasticsearch/v8"
	"github.com/redis/go-redis/v9"
)

// Services æœåŠ¡é›†åˆ
type Services struct {
	// ä¸šåŠ¡æœåŠ¡
	Auth      *auth.Service
	Chat      *chat.Service
	Agent     *agent.Service
	Knowledge *knowledge.Service
	Chunk     *chunk.Service
	Tool      *tool.Service
	FAQ       *faq.Service
	FAQEntry  *faq.EntryService // å¢å¼ºç‰ˆFAQæœåŠ¡
	Initialization *initialization.Service // åˆå§‹åŒ–æœåŠ¡
	Model     *svcModel.Service // æ¨¡å‹ç®¡ç†æœåŠ¡
	Evaluation *evaluation.Service // è¯„ä¼°æœåŠ¡
	MCP       *svcmcp.Service // MCP æœåŠ¡ç®¡ç†
	Tenant    *svctenant.Service // ç§Ÿæˆ·ç®¡ç†
	Tag       *svctag.Service // æ ‡ç­¾ç®¡ç†æœåŠ¡
	File      *file.Service // æ–‡ä»¶å­˜å‚¨æœåŠ¡
	Dataset   *dataset.Service // æ•°æ®é›†æœåŠ¡

	// æ–°å¢æœåŠ¡
	RewriteSvc *rewrite.Service
	EventBus   *event.EventBus

	// é…ç½®
	Config     *config.Config
	SessionMgr *session.Manager

	// Eino ç»„ä»¶ï¼ˆç›´æ¥ä½¿ç”¨ eino ç±»å‹ï¼Œæ— å°è£…ï¼‰
	AllTools []einotool.BaseTool
	Embedder embedding.Embedder

	// RAG ç»„ä»¶
	ChatModel  ecomodel.ChatModel             // ç”¨äºæŸ¥è¯¢å¤„ç†å’Œé‡æ’çš„ ChatModel
	Retriever  retriever.Retriever         // ES8 æ£€ç´¢å™¨
	Query      *query.Optimizer            // æŸ¥è¯¢ä¼˜åŒ–å™¨
	Rerankers  []types.Reranker            // é‡æ’å™¨åˆ—è¡¨ï¼ˆä½¿ç”¨ types åŒ…é¿å…å¾ªç¯å¯¼å…¥ï¼‰
}

// NewServices åˆ›å»ºæ‰€æœ‰æœåŠ¡
// å‚è€ƒ eino-examplesï¼Œä½¿ç”¨ç®€å•çš„ newXxx() å‡½æ•°ç›´æ¥åˆå§‹åŒ– eino ç»„ä»¶
func NewServices(repo *repository.Repositories, cfg *config.Config, redisClient *redis.Client) (*Services, error) {
	ctx := context.Background()

	// è®¾ç½® Eino å…¨å±€å›è°ƒï¼ˆç”¨äºæ—¥å¿—è¿½è¸ªï¼‰
	callback.SetupGlobalCallbacks(cfg.App.Debug)

	// åˆ›å»º Session ç®¡ç†å™¨
	sessionMgr := session.NewManager(redisClient)

	// åˆ›å»º ChatModel (ç”¨äºæŸ¥è¯¢å¤„ç†å’Œé‡æ’)
	chatModel, err := newChatModel(ctx, cfg)
	if err != nil {
		log.Printf("Warning: failed to create chat model: %v", err)
	}

	// åˆ›å»º Embedding å™¨
	embedder := newEmbedder(ctx, cfg)

	// åˆ›å»º ES8 Retriever
	var retriever *es8.Retriever
	if embedder != nil {
		retriever = newES8Retriever(ctx, cfg, embedder)
	}

	// åˆ›å»ºæŸ¥è¯¢ä¼˜åŒ–å™¨
	var queryOptimizer *query.Optimizer
	if chatModel != nil {
		queryOptimizer = query.NewOptimizer(chatModel, 3)
	}

	// åˆ›å»ºé‡æ’å™¨
	rerankers := newRerankers(ctx, cfg, chatModel)

	// åˆå§‹åŒ–å·¥å…·
	allTools := newTools(ctx, cfg, retriever, repo)
	log.Printf("Initialized %d tools", len(allTools))

	// åˆ›å»ºæŸ¥è¯¢é‡å†™æœåŠ¡
	rewriteSvc := rewrite.NewService(chatModel, rewrite.DefaultConfig())

	// åˆ›å»ºäº‹ä»¶æ€»çº¿
	eventBus := event.NewEventBus(newEventStore(redisClient))

	// åˆ›å»ºæ–‡ä»¶å­˜å‚¨æœåŠ¡
	fileSvc := newFileService(repo, cfg)

	return &Services{
		Auth:      auth.NewService(repo),
		Chat:      chat.NewService(repo, chatModel),
		Agent:     agent.NewService(repo, cfg, allTools),
		Knowledge: knowledge.NewService(repo, cfg, embedder),
		Chunk:     chunk.NewService(repo),
		Tool:      tool.NewService(repo),
		FAQ:       faq.NewService(repo),
		FAQEntry:  faq.NewEntryService(repo),
		Initialization: initialization.NewService(repo),
		Model:     svcModel.NewService(repo.Model),
		Evaluation: evaluation.NewService(repo),
		MCP:       svcmcp.NewService(repo),
		Tenant:    svctenant.NewService(repo),
		Tag:       svctag.NewService(repo),
		File:      fileSvc,
		Dataset:   dataset.NewService(repo),

		// æ–°å¢æœåŠ¡
		RewriteSvc: rewriteSvc,
		EventBus:   eventBus,

		Config:     cfg,
		SessionMgr: sessionMgr,

		AllTools:  allTools,
		Embedder:  embedder,
		ChatModel: chatModel,
		Retriever: retriever,
		Query:     queryOptimizer,
		Rerankers: rerankers,
	}, nil
}

// newChatModel åˆ›å»º ChatModel
func newChatModel(ctx context.Context, cfg *config.Config) (ecomodel.ChatModel, error) {
	aiCfg := cfg.AI

	var apiKey, baseURL, modelName string

	switch aiCfg.Provider {
	case "openai":
		apiKey = aiCfg.OpenAI.APIKey
		baseURL = aiCfg.OpenAI.BaseURL
		modelName = aiCfg.OpenAI.Model
	case "alibaba", "qwen", "dashscope":
		apiKey = aiCfg.Alibaba.AccessKeySecret
		baseURL = "https://dashscope.aliyuncs.com/compatible-mode/v1"
		modelName = aiCfg.Alibaba.Model
	case "deepseek":
		apiKey = aiCfg.DeepSeek.APIKey
		baseURL = aiCfg.DeepSeek.BaseURL
		modelName = aiCfg.DeepSeek.Model
	default:
		return nil, fmt.Errorf("unsupported ai provider: %s", aiCfg.Provider)
	}

	if apiKey == "" {
		return nil, fmt.Errorf("api_key is required for provider: %s", aiCfg.Provider)
	}

	if modelName == "" {
		modelName = "gpt-4o-mini"
	}

	return openai.NewChatModel(ctx, &openai.ChatModelConfig{
		APIKey:  apiKey,
		BaseURL: baseURL,
		Model:   modelName,
	})
}

// newToolCallingChatModel åˆ›å»ºæ”¯æŒå·¥å…·è°ƒç”¨çš„ ChatModel
func newToolCallingChatModel(ctx context.Context, cfg *config.Config) (ecomodel.ToolCallingChatModel, error) {
	aiCfg := cfg.AI

	var apiKey, baseURL, modelName string

	switch aiCfg.Provider {
	case "openai":
		apiKey = aiCfg.OpenAI.APIKey
		baseURL = aiCfg.OpenAI.BaseURL
		modelName = aiCfg.OpenAI.Model
	case "alibaba", "qwen", "dashscope":
		apiKey = aiCfg.Alibaba.AccessKeySecret
		baseURL = "https://dashscope.aliyuncs.com/compatible-mode/v1"
		modelName = aiCfg.Alibaba.Model
	case "deepseek":
		apiKey = aiCfg.DeepSeek.APIKey
		baseURL = aiCfg.DeepSeek.BaseURL
		modelName = aiCfg.DeepSeek.Model
	default:
		return nil, fmt.Errorf("unsupported ai provider: %s", aiCfg.Provider)
	}

	if apiKey == "" {
		return nil, fmt.Errorf("api_key is required for provider: %s", aiCfg.Provider)
	}

	if modelName == "" {
		modelName = "gpt-4o-mini"
	}

	temperature := float32(0.7)

	return openai.NewChatModel(ctx, &openai.ChatModelConfig{
		APIKey:      apiKey,
		BaseURL:     baseURL,
		Model:       modelName,
		Temperature: &temperature,
	})
}

// newEmbedder åˆ›å»º Embedding å™¨
func newEmbedder(ctx context.Context, cfg *config.Config) embedding.Embedder {
	embCfg := cfg.AI.Embedding

	var apiKey, model string
	var timeout int

	switch embCfg.Provider {
	case "alibaba", "qwen", "dashscope", "":
		apiKey = embCfg.APIKey
		model = embCfg.Model
		timeout = embCfg.Timeout
	case "openai":
		apiKey = embCfg.APIKey
		model = embCfg.Model
		timeout = embCfg.Timeout
	default:
		log.Printf("Warning: unsupported embedding provider: %s", embCfg.Provider)
		return nil
	}

	if apiKey == "" {
		log.Printf("Warning: embedding api_key is empty")
		return nil
	}

	if model == "" {
		model = "text-embedding-v3"
	}

	embConfig := &dashscope.EmbeddingConfig{
		APIKey: apiKey,
		Model:  model,
	}

	if timeout > 0 {
		embConfig.Timeout = time.Duration(timeout) * time.Second
	}

	if embCfg.Dimensions > 0 {
		embConfig.Dimensions = &embCfg.Dimensions
	}

	embedder, err := dashscope.NewEmbedder(ctx, embConfig)
	if err != nil {
		log.Printf("Warning: failed to create embedder: %v", err)
		return nil
	}

	return embedder
}

// newES8Retriever åˆ›å»º ES8 æ£€ç´¢å™¨
func newES8Retriever(ctx context.Context, cfg *config.Config, embedder embedding.Embedder) *es8.Retriever {
	esCfg := cfg.Elastic

	if esCfg.Host == "" {
		log.Printf("Warning: elasticsearch host not configured")
		return nil
	}

	esClient, err := elasticsearch.NewClient(elasticsearch.Config{
		Addresses: []string{esCfg.Host},
		Username:  esCfg.Username,
		Password:  esCfg.Password,
	})
	if err != nil {
		log.Printf("Warning: failed to create es client: %v", err)
		return nil
	}

	indexName := esCfg.IndexPrefix + "_chunks"

	retriever, err := es8.NewRetriever(ctx, &es8.RetrieverConfig{
		Client:     esClient,
		Index:      indexName,
		TopK:       10,
		SearchMode: search_mode.SearchModeDenseVectorSimilarity(search_mode.DenseVectorSimilarityTypeCosineSimilarity, "content_vector"),
		Embedding:  embedder,
	})
	if err != nil {
		log.Printf("Warning: failed to create retriever: %v", err)
		return nil
	}

	return retriever
}

// newWebSearchTool åˆ›å»ºç½‘ç»œæœç´¢å·¥å…·
func newWebSearchTool(ctx context.Context) einotool.InvokableTool {
	searchTool, err := duckduckgov2.NewTextSearchTool(ctx, &duckduckgov2.Config{
		ToolName: "web_search",
		ToolDesc: "Search the web for current information using DuckDuckGo. Use this when you need up-to-date information or the knowledge base doesn't have the answer.",
		MaxResults: 10,
	})
	if err != nil {
		log.Printf("Warning: failed to create web search tool: %v", err)
		return &stubTool{name: "web_search"}
	}

	return searchTool
}

// newTools åˆå§‹åŒ–æ‰€æœ‰å·¥å…·
func newTools(ctx context.Context, cfg *config.Config, retriever *es8.Retriever, repo *repository.Repositories) []einotool.BaseTool {
	tools := []einotool.BaseTool{}

	// æ·»åŠ ç½‘ç»œæœç´¢å·¥å…· (eino-ext duckduckgo)
	tools = append(tools, newWebSearchTool(ctx))

	// æ·»åŠ  HTTP è¯·æ±‚å·¥å…· (eino-ext httprequest)
	httpTools, err := httptool.NewToolKit(ctx, &httptool.Config{})
	if err != nil {
		log.Printf("Warning: failed to create http tools: %v", err)
	} else {
		tools = append(tools, httpTools...)
	}

	// æ·»åŠ  Wikipedia æœç´¢å·¥å…· (eino-ext wikipedia)
	wikiTool, err := wikipediatool.NewTool(ctx, &wikipediatool.Config{
		Language: "zh", // ä¸­æ–‡ Wikipedia
		TopK:     3,
	})
	if err != nil {
		log.Printf("Warning: failed to create wikipedia tool: %v", err)
	} else {
		tools = append(tools, wikiTool)
	}

	// æ·»åŠ é¡ºåºæ€è€ƒå·¥å…· (eino-ext sequentialthinking)
	thinkTool, err := sequencethinking.NewTool()
	if err != nil {
		log.Printf("Warning: failed to create sequentialthinking tool: %v", err)
	} else {
		tools = append(tools, thinkTool)
	}

	// æ·»åŠ  todo_write å·¥å…·
	tools = append(tools, newTodoWriteTool())

	// æ·»åŠ çŸ¥è¯†åº“æœç´¢å·¥å…·
	if retriever != nil {
		tools = append(tools, newKnowledgeSearchTool(retriever))
	}

	// æ·»åŠ æ–‡æ¡£ç›¸å…³å·¥å…·
	if repo != nil {
		tools = append(tools, newDocumentInfoTool(repo))
		tools = append(tools, newListChunksTool(repo))
		tools = append(tools, newGrepChunksTool(repo))
	}

	// æ·»åŠ æ•°æ®åº“å·¥å…·
	// æ³¨æ„: æ•°æ®åº“å·¥å…·éœ€è¦ sessionID å’Œ tenantIDï¼Œåœ¨ Agent è¿è¡Œæ—¶åŠ¨æ€åˆ›å»º
	// è¿™é‡Œä½¿ç”¨ stub å ä½ï¼Œå®é™…ä½¿ç”¨æ—¶åœ¨ Agent é…ç½®ä¸­æ·»åŠ 

	return tools
}

// stubTool å ä½å·¥å…·
type stubTool struct {
	name string
}

func (t *stubTool) Info(ctx context.Context) (*schema.ToolInfo, error) {
	return &schema.ToolInfo{
		Name: t.name,
		Desc: t.name + " (unavailable)",
		ParamsOneOf: schema.NewParamsOneOfByParams(map[string]*schema.ParameterInfo{
			"query": {
				Type:     schema.String,
				Desc:     "The query string",
				Required: true,
			},
		}),
	}, nil
}

func (t *stubTool) InvokableRun(ctx context.Context, argumentsInJSON string, opts ...einotool.Option) (string, error) {
	return fmt.Sprintf(`{"error":"%s is not available"}`, t.name), nil
}

// ========== todo_write å·¥å…· ==========

// PlanStep è®¡åˆ’æ­¥éª¤
type PlanStep struct {
	ID          string `json:"id" jsonschema_description:"æ­¥éª¤ID"`
	Description string `json:"description" jsonschema_description:"æ­¥éª¤æè¿°"`
	Status      string `json:"status" jsonschema_description:"çŠ¶æ€: pending, in_progress, completed"`
}

// TodoWriteInput todo_write è¾“å…¥å‚æ•°
type TodoWriteInput struct {
	Task  string     `json:"task" jsonschema_description:"ä»»åŠ¡æè¿°"`
	Steps []PlanStep `json:"steps" jsonschema_description:"ä»»åŠ¡æ­¥éª¤åˆ—è¡¨"`
}

// newTodoWriteTool åˆ›å»ºä»»åŠ¡è®¡åˆ’å·¥å…·
// ä½¿ç”¨ utils.InferTool è‡ªåŠ¨ç”Ÿæˆ ToolInfo
func newTodoWriteTool() einotool.InvokableTool {
	t, err := utils.InferTool(
		"todo_write",
		`åˆ›å»ºå’Œç®¡ç†ç»“æ„åŒ–çš„æ£€ç´¢ä»»åŠ¡åˆ—è¡¨ã€‚ç”¨äºè·Ÿè¸ªå¤æ‚ä»»åŠ¡çš„è¿›åº¦ã€‚

**ä½¿ç”¨åœºæ™¯**ï¼š
- å¤æ‚å¤šæ­¥éª¤ä»»åŠ¡ï¼ˆ3ä¸ªæˆ–ä»¥ä¸Šæ­¥éª¤ï¼‰
- éœ€è¦ä»”ç»†è§„åˆ’çš„æ“ä½œ
- ç”¨æˆ·æ˜ç¡®è¯·æ±‚åˆ›å»ºä»»åŠ¡åˆ—è¡¨

**ä»»åŠ¡çŠ¶æ€**ï¼š
- pending: æœªå¼€å§‹
- in_progress: è¿›è¡Œä¸­ï¼ˆåŒæ—¶åªèƒ½æœ‰ä¸€ä¸ªï¼‰
- completed: å·²å®Œæˆ

**é‡è¦**ï¼š
- ä»…åŒ…å«æ£€ç´¢/ç ”ç©¶ä»»åŠ¡ï¼Œä¸åŒ…å«æ€»ç»“ä»»åŠ¡
- å®Œæˆæ‰€æœ‰æ£€ç´¢ä»»åŠ¡åï¼Œä½¿ç”¨ thinking å·¥å…·è¿›è¡Œæ€»ç»“`,
		func(ctx context.Context, input *TodoWriteInput) (string, error) {
			if input.Task == "" {
				input.Task = "æœªæä¾›ä»»åŠ¡æè¿°"
			}
			return generateTodoOutput(input.Task, input.Steps), nil
		},
	)
	if err != nil {
		log.Printf("Warning: failed to create todo_write tool: %v", err)
		return nil
	}
	return t
}

// ========== çŸ¥è¯†åº“æœç´¢å·¥å…· ==========

// KnowledgeSearchInput çŸ¥è¯†åº“æœç´¢è¾“å…¥
type KnowledgeSearchInput struct {
	Query string `json:"query" jsonschema_description:"The search query" jsonschema_required:"true"`
	TopK  int    `json:"top_k" jsonschema_description:"Number of results (default 10)"`
}

// KnowledgeSearchOutput çŸ¥è¯†åº“æœç´¢è¾“å‡º
type KnowledgeSearchOutput struct {
	Query   string                 `json:"query"`
	Total   int                    `json:"total"`
	Results []map[string]interface{} `json:"results"`
}

// newKnowledgeSearchTool åˆ›å»ºçŸ¥è¯†åº“æœç´¢å·¥å…·
func newKnowledgeSearchTool(r *es8.Retriever) einotool.InvokableTool {
	t, err := utils.InferTool(
		"knowledge_search",
		"Searches the knowledge base for relevant information using semantic and keyword search.",
		func(ctx context.Context, input *KnowledgeSearchInput) (*KnowledgeSearchOutput, error) {
			if input.Query == "" {
				return nil, fmt.Errorf("query is required")
			}
			if input.TopK <= 0 {
				input.TopK = 10
			}

			docs, err := r.Retrieve(ctx, input.Query, retriever.WithTopK(input.TopK))
			if err != nil {
				return nil, fmt.Errorf("retriever failed: %w", err)
			}

			results := make([]map[string]interface{}, 0, len(docs))
			for _, doc := range docs {
				result := map[string]interface{}{
					"content": doc.Content,
					"score":   doc.Score(),
				}
				if doc.MetaData != nil {
					if title, ok := doc.MetaData["title"].(string); ok {
						result["title"] = title
					}
				}
				results = append(results, result)
			}

			return &KnowledgeSearchOutput{
				Query:   input.Query,
				Total:   len(results),
				Results: results,
			}, nil
		},
	)
	if err != nil {
		log.Printf("Warning: failed to create knowledge_search tool: %v", err)
		return nil
	}
	return t
}

// ========== æ–‡æ¡£ç›¸å…³å·¥å…· ==========

// DocumentInfoInput æ–‡æ¡£ä¿¡æ¯è¾“å…¥
type DocumentInfoInput struct {
	DocumentIDs []string `json:"document_ids" jsonschema_description:"æ–‡æ¡£ ID åˆ—è¡¨ï¼Œæœ€å¤š 10 ä¸ª" jsonschema_required:"true"`
}

// DocumentInfoOutput æ–‡æ¡£ä¿¡æ¯è¾“å‡º
type DocumentInfoOutput struct {
	Count     int                    `json:"count"`
	Documents []map[string]interface{} `json:"documents"`
}

// newDocumentInfoTool åˆ›å»ºæ–‡æ¡£ä¿¡æ¯å·¥å…·
func newDocumentInfoTool(repo *repository.Repositories) einotool.InvokableTool {
	t, err := utils.InferTool(
		"get_document_info",
		"è·å–æ–‡æ¡£çš„è¯¦ç»†å…ƒæ•°æ®ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€æ–‡ä»¶åã€å¤§å°ã€åˆ†å—æ•°é‡ç­‰ã€‚ç”¨äºæŸ¥è¯¢æ–‡æ¡£åŸºæœ¬ä¿¡æ¯å’Œå¤„ç†çŠ¶æ€ã€‚",
		func(ctx context.Context, input *DocumentInfoInput) (*DocumentInfoOutput, error) {
			if len(input.DocumentIDs) == 0 {
				return nil, fmt.Errorf("document_ids is required")
			}
			if len(input.DocumentIDs) > 10 {
				return nil, fmt.Errorf("maximum 10 document IDs allowed")
			}

			results := make([]map[string]interface{}, 0)
			for _, docID := range input.DocumentIDs {
				doc, err := repo.Knowledge.GetDocumentByID(docID)
				if err != nil {
					continue
				}
				chunks, _ := repo.Knowledge.GetChunksByDocumentID(docID)

				results = append(results, map[string]interface{}{
					"id":           doc.ID,
					"title":        doc.Title,
					"file_name":    doc.FileName,
					"file_size":    doc.FileSize,
					"content_type": doc.ContentType,
					"status":       doc.Status,
					"chunk_count":  len(chunks),
					"created_at":   doc.CreatedAt,
				})
			}

			return &DocumentInfoOutput{
				Count:     len(results),
				Documents: results,
			}, nil
		},
	)
	if err != nil {
		log.Printf("Warning: failed to create get_document_info tool: %v", err)
		return nil
	}
	return t
}

// ========== åˆ†å—åˆ—è¡¨å·¥å…· ==========

// ListChunksInput åˆ—å‡ºåˆ†å—è¾“å…¥
type ListChunksInput struct {
	DocumentID string `json:"document_id" jsonschema_description:"æ–‡æ¡£ ID" jsonschema_required:"true"`
}

// ChunkItem åˆ†å—é¡¹
type ChunkItem struct {
	ID         string `json:"id"`
	ChunkIndex int    `json:"chunk_index"`
	Content    string `json:"content"`
}

// ListChunksOutput åˆ—å‡ºåˆ†å—è¾“å‡º
type ListChunksOutput struct {
	DocumentID string      `json:"document_id"`
	Title      string      `json:"title"`
	Total      int         `json:"total"`
	Chunks     []ChunkItem `json:"chunks"`
}

// newListChunksTool åˆ›å»ºåˆ—å‡ºåˆ†å—å·¥å…·
func newListChunksTool(repo *repository.Repositories) einotool.InvokableTool {
	t, err := utils.InferTool(
		"list_chunks",
		"è·å–æŒ‡å®šæ–‡æ¡£çš„æ‰€æœ‰åˆ†å—å†…å®¹ã€‚ç”¨äºæŸ¥çœ‹æ–‡æ¡£çš„å®Œæ•´åˆ†å—åˆ—è¡¨ã€‚",
		func(ctx context.Context, input *ListChunksInput) (*ListChunksOutput, error) {
			if input.DocumentID == "" {
				return nil, fmt.Errorf("document_id is required")
			}

			doc, err := repo.Knowledge.GetDocumentByID(input.DocumentID)
			if err != nil {
				return nil, fmt.Errorf("document not found: %w", err)
			}

			chunks, err := repo.Knowledge.GetChunksByDocumentID(input.DocumentID)
			if err != nil {
				return nil, fmt.Errorf("failed to get chunks: %w", err)
			}

			chunkList := make([]ChunkItem, 0, len(chunks))
			for _, c := range chunks {
				chunkList = append(chunkList, ChunkItem{
					ID:         c.ID,
					ChunkIndex: c.ChunkIndex,
					Content:    c.Content,
				})
			}

			return &ListChunksOutput{
				DocumentID: doc.ID,
				Title:      doc.Title,
				Total:      len(chunks),
				Chunks:     chunkList,
			}, nil
		},
	)
	if err != nil {
		log.Printf("Warning: failed to create list_chunks tool: %v", err)
		return nil
	}
	return t
}

// ========== åˆ†å—æœç´¢å·¥å…· ==========

// GrepChunksInput åˆ†å—æœç´¢è¾“å…¥
type GrepChunksInput struct {
	Pattern    string `json:"pattern" jsonschema_description:"æœç´¢æ¨¡å¼ï¼ˆæ–‡æœ¬ï¼‰" jsonschema_required:"true"`
	DocumentID string `json:"document_id" jsonschema_description:"å¯é€‰ï¼šé™åˆ¶åœ¨ç‰¹å®šæ–‡æ¡£ä¸­æœç´¢"`
}

// GrepChunkItem æœç´¢ç»“æœé¡¹
type GrepChunkItem struct {
	ID         string `json:"id"`
	DocumentID string `json:"document_id"`
	ChunkIndex int    `json:"chunk_index"`
	Content    string `json:"content"`
}

// GrepChunksOutput åˆ†å—æœç´¢è¾“å‡º
type GrepChunksOutput struct {
	Pattern string         `json:"pattern"`
	Count   int            `json:"count"`
	Matches []GrepChunkItem `json:"matches"`
}

// newGrepChunksTool åˆ›å»ºåˆ†å—æœç´¢å·¥å…·
func newGrepChunksTool(repo *repository.Repositories) einotool.InvokableTool {
	t, err := utils.InferTool(
		"grep_chunks",
		"åœ¨æ–‡æ¡£åˆ†å—ä¸­æœç´¢åŒ…å«ç‰¹å®šæ–‡æœ¬çš„å†…å®¹ã€‚æ”¯æŒç²¾ç¡®æ–‡æœ¬åŒ¹é…ã€‚",
		func(ctx context.Context, input *GrepChunksInput) (*GrepChunksOutput, error) {
			if input.Pattern == "" {
				return nil, fmt.Errorf("pattern is required")
			}

			var chunks []*model.DocumentChunk
			var err error

			if input.DocumentID != "" {
				// æœç´¢ç‰¹å®šæ–‡æ¡£çš„åˆ†å—
				chunks, err = repo.Knowledge.GetChunksByDocumentID(input.DocumentID)
				if err != nil {
					return nil, fmt.Errorf("failed to get chunks: %w", err)
				}
			}

			// è¿‡æ»¤åŒ…å«åŒ¹é…å†…å®¹çš„åˆ†å—
			matches := make([]GrepChunkItem, 0)
			for _, c := range chunks {
				if containsIgnoreCase(c.Content, input.Pattern) {
					matches = append(matches, GrepChunkItem{
						ID:         c.ID,
						DocumentID: c.DocumentID,
						ChunkIndex: c.ChunkIndex,
						Content:    c.Content,
					})
				}
			}

			return &GrepChunksOutput{
				Pattern: input.Pattern,
				Count:   len(matches),
				Matches: matches,
			}, nil
		},
	)
	if err != nil {
		log.Printf("Warning: failed to create grep_chunks tool: %v", err)
		return nil
	}
	return t
}

// TodoWriteTool ä»»åŠ¡è®¡åˆ’å·¥å…·ï¼ˆå·²å¼ƒç”¨ï¼Œä¿ç•™ç”¨äºå…¼å®¹ï¼‰
// ä½¿ç”¨ utils.InferTool é‡æ„åä¸å†éœ€è¦æ­¤ç±»å‹
type TodoWriteTool struct{}

// generateTodoOutput ç”Ÿæˆ todo è¾“å‡º
func generateTodoOutput(task string, steps []PlanStep) string {
	output := "## è®¡åˆ’å·²åˆ›å»º\n\n"
	output += fmt.Sprintf("**ä»»åŠ¡**: %s\n\n", task)

	if len(steps) == 0 {
		output += "æ³¨æ„ï¼šæœªæä¾›å…·ä½“æ­¥éª¤ã€‚å»ºè®®åˆ›å»º3-7ä¸ªæ£€ç´¢ä»»åŠ¡ã€‚\n\n"
		output += "å»ºè®®çš„æ£€ç´¢æµç¨‹ï¼š\n"
		output += "1. ä½¿ç”¨ grep_chunks æœç´¢å…³é”®è¯å®šä½ç›¸å…³æ–‡æ¡£\n"
		output += "2. ä½¿ç”¨ knowledge_search è¿›è¡Œè¯­ä¹‰æœç´¢è·å–ç›¸å…³å†…å®¹\n"
		output += "3. ä½¿ç”¨ list_chunks è·å–å…³é”®æ–‡æ¡£çš„å®Œæ•´å†…å®¹\n"
		output += "4. ä½¿ç”¨ web_search è·å–è¡¥å……ä¿¡æ¯ï¼ˆå¦‚éœ€è¦ï¼‰\n"
		return output
	}

	// ç»Ÿè®¡ä»»åŠ¡çŠ¶æ€
	pendingCount := 0
	inProgressCount := 0
	completedCount := 0
	for _, step := range steps {
		switch step.Status {
		case "pending":
			pendingCount++
		case "in_progress":
			inProgressCount++
		case "completed":
			completedCount++
		}
	}
	totalCount := len(steps)
	remainingCount := pendingCount + inProgressCount

	output += "**ä»»åŠ¡æ­¥éª¤**:\n\n"
	for i, step := range steps {
		output += formatTodoStep(i+1, step)
	}

	// æ·»åŠ è¿›åº¦æ±‡æ€»
	output += "\n## ä»»åŠ¡è¿›åº¦\n"
	output += fmt.Sprintf("æ€»è®¡: %d ä¸ªä»»åŠ¡ | ", totalCount)
	output += fmt.Sprintf("âœ… å·²å®Œæˆ: %d | ", completedCount)
	output += fmt.Sprintf("ğŸ”„ è¿›è¡Œä¸­: %d | ", inProgressCount)
	output += fmt.Sprintf("â³ å¾…å¤„ç†: %d\n\n", pendingCount)

	// æ·»åŠ æé†’
	output += "## âš ï¸ é‡è¦æé†’\n"
	if remainingCount > 0 {
		output += fmt.Sprintf("**è¿˜æœ‰ %d ä¸ªä»»åŠ¡æœªå®Œæˆï¼**\n\n", remainingCount)
		output += "**å¿…é¡»å®Œæˆæ‰€æœ‰ä»»åŠ¡åæ‰èƒ½æ€»ç»“æˆ–å¾—å‡ºç»“è®ºã€‚**\n\n"
		output += "ä¸‹ä¸€æ­¥æ“ä½œï¼š\n"
		if inProgressCount > 0 {
			output += "- ç»§ç»­å®Œæˆå½“å‰è¿›è¡Œä¸­çš„ä»»åŠ¡\n"
		}
		if pendingCount > 0 {
			output += fmt.Sprintf("- å¼€å§‹å¤„ç† %d ä¸ªå¾…å¤„ç†ä»»åŠ¡\n", pendingCount)
		}
		output += "- å®Œæˆæ¯ä¸ªä»»åŠ¡åï¼Œæ›´æ–° todo_write æ ‡è®°ä¸º completed\n"
		output += "- æ‰€æœ‰ä»»åŠ¡å®Œæˆåï¼Œä½¿ç”¨ thinking å·¥å…·ç”Ÿæˆæœ€ç»ˆæ€»ç»“\n"
	} else {
		output += "âœ… **æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼**\n\n"
		output += "ç°åœ¨å¯ä»¥ï¼š\n"
		output += "- ç»¼åˆæ‰€æœ‰ä»»åŠ¡çš„å‘ç°\n"
		output += "- ä½¿ç”¨ thinking å·¥å…·ç”Ÿæˆå®Œæ•´çš„æœ€ç»ˆç­”æ¡ˆ\n"
	}

	return output
}

// formatTodoStep æ ¼å¼åŒ–å•ä¸ªä»»åŠ¡æ­¥éª¤
func formatTodoStep(index int, step PlanStep) string {
	statusEmoji := map[string]string{
		"pending":     "â³",
		"in_progress": "ğŸ”„",
		"completed":   "âœ…",
	}

	emoji, ok := statusEmoji[step.Status]
	if !ok {
		emoji = "â³"
	}

	return fmt.Sprintf("%d. %s [%s] %s\n", index, emoji, step.Status, step.Description)
}

// GetToolsByName æ ¹æ®åç§°è·å–å·¥å…·
func GetToolsByName(ctx context.Context, names []string, allTools []einotool.BaseTool) ([]einotool.BaseTool, error) {
	if len(names) == 0 {
		return allTools, nil
	}

	toolMap := make(map[string]einotool.BaseTool)
	for _, t := range allTools {
		info, err := t.Info(ctx)
		if err != nil {
			continue
		}
		toolMap[info.Name] = t
	}

	result := make([]einotool.BaseTool, 0, len(names))
	for _, name := range names {
		t, ok := toolMap[name]
		if !ok {
			return nil, fmt.Errorf("tool not found: %s", name)
		}
		result = append(result, t)
	}

	return result, nil
}

// ListToolNames åˆ—å‡ºæ‰€æœ‰å·¥å…·åç§°
func ListToolNames(ctx context.Context, allTools []einotool.BaseTool) []string {
	names := make([]string, 0, len(allTools))
	for _, t := range allTools {
		info, err := t.Info(ctx)
		if err != nil {
			continue
		}
		names = append(names, info.Name)
	}
	return names
}

// newRerankers åˆ›å»ºé»˜è®¤çš„é‡æ’å™¨åˆ—è¡¨
func newRerankers(ctx context.Context, cfg *config.Config, chatModel ecomodel.ChatModel) []types.Reranker {
	rerankers := []types.Reranker{}

	// æ·»åŠ åˆ†æ•°é‡æ’ï¼ˆè½»é‡çº§ï¼Œå§‹ç»ˆå¯ç”¨ï¼‰
	// è¿™é‡Œç›´æ¥å®ç°ç®€å•é‡æ’ï¼Œé¿å…é¢å¤–å¯¼å…¥
	rerankers = append(rerankers, &scoreReranker{})

	// LLM é‡æ’ï¼ˆå¦‚æœæœ‰ ChatModelï¼‰
	if chatModel != nil {
		rerankers = append(rerankers, &llmRerankerWrapper{
			chatModel: chatModel,
			topN:      5,
		})
	}

	return rerankers
}

// scoreReranker åˆ†æ•°é‡æ’å™¨ï¼ˆç®€å•å®ç°ï¼‰
type scoreReranker struct{}

func (r *scoreReranker) Rerank(ctx context.Context, query string, docs []*schema.Document) ([]*schema.Document, error) {
	if len(docs) <= 1 {
		return docs, nil
	}

	// å¤åˆ¶å¹¶æŒ‰åˆ†æ•°æ’åº
	sorted := make([]*schema.Document, len(docs))
	copy(sorted, docs)

	// ç®€å•æ’åº
	for i := 0; i < len(sorted); i++ {
		for j := i + 1; j < len(sorted); j++ {
			if sorted[j].Score() > sorted[i].Score() {
				sorted[i], sorted[j] = sorted[j], sorted[i]
			}
		}
	}

	return sorted, nil
}

// llmRerankerWrapper LLM é‡æ’å™¨åŒ…è£…
type llmRerankerWrapper struct {
	chatModel ecomodel.ChatModel
	topN      int
}

func (r *llmRerankerWrapper) Rerank(ctx context.Context, query string, docs []*schema.Document) ([]*schema.Document, error) {
	if len(docs) <= r.topN || r.chatModel == nil {
		return docs, nil
	}

	// æ„å»ºæ–‡æ¡£æè¿°
	docDesc := ""
	for i, doc := range docs {
		content := doc.Content
		if len(content) > 200 {
			content = content[:200] + "..."
		}
		docDesc += fmt.Sprintf("%d. %s\n", i+1, content)
	}

	// è°ƒç”¨ LLM
	prompt := fmt.Sprintf(`ä½ æ˜¯ä¸€ä¸ªæ£€ç´¢ç»“æœé‡æ’ä¸“å®¶ã€‚è¯·æ ¹æ®æŸ¥è¯¢çš„ç›¸å…³æ€§ï¼Œå¯¹æ£€ç´¢åˆ°çš„æ–‡æ¡£è¿›è¡Œæ’åºã€‚

æŸ¥è¯¢ï¼š%s

æ£€ç´¢åˆ°çš„æ–‡æ¡£ï¼š
%s

è¯·æŒ‰ç…§ä¸æŸ¥è¯¢çš„ç›¸å…³åº¦ä»é«˜åˆ°ä½æ’åºï¼Œè¾“å‡ºæ’åºåçš„æ–‡æ¡£ç¼–å·ï¼ˆç”¨é€—å·åˆ†éš”ï¼Œå¦‚ï¼š1,3,2,4,5ï¼‰ã€‚

æ’åºç»“æœï¼š`, query, docDesc)

	messages := []*schema.Message{
		{Role: schema.System, Content: "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ£€ç´¢ç»“æœé‡æ’åŠ©æ‰‹ã€‚"},
		{Role: schema.User, Content: prompt},
	}

	resp, err := r.chatModel.Generate(ctx, messages)
	if err != nil {
		return docs, nil // å¤±è´¥æ—¶è¿”å›åŸé¡ºåº
	}

	// è§£ææ’åºç»“æœï¼ˆç®€åŒ–ç‰ˆï¼‰
	indices := extractNumbersFromOutput(resp.Content)
	if len(indices) == 0 {
		return docs[:r.topN], nil
	}

	// åº”ç”¨æ’åº
	result := make([]*schema.Document, 0, minInt(r.topN, len(indices)))
	for i, idx := range indices {
		if idx >= 0 && idx < len(docs) && i < r.topN {
			result = append(result, docs[idx])
		}
	}

	if len(result) == 0 {
		return docs[:r.topN], nil
	}

	return result, nil
}

func extractNumbersFromOutput(s string) []int {
	nums := make([]int, 0)
	current := 0

	for _, ch := range s {
		if ch >= '0' && ch <= '9' {
			current = current*10 + int(ch-'0')
		} else {
			if current > 0 {
				nums = append(nums, current)
				current = 0
			}
		}
	}
	if current > 0 {
		nums = append(nums, current)
	}

	return nums
}

func minInt(a, b int) int {
	if a < b {
		return a
	}
	return b
}

// ========== å­˜å‚¨å®ç° ==========

// eventStoreImpl äº‹ä»¶å­˜å‚¨å®ç°
type eventStoreImpl struct {
	redisClient *redis.Client
}

// newEventStore åˆ›å»ºäº‹ä»¶å­˜å‚¨
func newEventStore(redisClient *redis.Client) event.Store {
	return &eventStoreImpl{redisClient: redisClient}
}

func (s *eventStoreImpl) SaveEvent(ctx context.Context, evt *event.Event) error {
	if s.redisClient == nil {
		return nil
	}

	key := fmt.Sprintf("events:%s", evt.SessionID)
	data, err := json.Marshal(evt)
	if err != nil {
		return err
	}

	// ä½¿ç”¨ LPUSH å­˜å‚¨äº‹ä»¶
	return s.redisClient.LPush(ctx, key, data).Err()
}

func (s *eventStoreImpl) GetEvents(ctx context.Context, sessionID string) ([]*event.Event, error) {
	if s.redisClient == nil {
		return []*event.Event{}, nil
	}

	key := fmt.Sprintf("events:%s", sessionID)
	values, err := s.redisClient.LRange(ctx, key, 0, -1).Result()
	if err != nil {
		return nil, err
	}

	events := make([]*event.Event, 0, len(values))
	for _, v := range values {
		var evt event.Event
		if err := json.Unmarshal([]byte(v), &evt); err != nil {
			continue
		}
		events = append(events, &evt)
	}

	return events, nil
}

func (s *eventStoreImpl) GetEventsByType(ctx context.Context, sessionID string, eventType event.EventType) ([]*event.Event, error) {
	events, err := s.GetEvents(ctx, sessionID)
	if err != nil {
		return nil, err
	}

	filtered := make([]*event.Event, 0)
	for _, evt := range events {
		if evt.EventType == eventType {
			filtered = append(filtered, evt)
		}
	}

	return filtered, nil
}

func (s *eventStoreImpl) ClearEvents(ctx context.Context, sessionID string) error {
	if s.redisClient == nil {
		return nil
	}

	key := fmt.Sprintf("events:%s", sessionID)
	return s.redisClient.Del(ctx, key).Err()
}

// containsIgnoreCase å¤§å°å†™ä¸æ•æ„Ÿæœç´¢
func containsIgnoreCase(s, substr string) bool {
	return len(s) >= len(substr) && (s == substr ||
		len(substr) == 0 ||
		containsIgnoreCaseWorker(s, substr))
}

func containsIgnoreCaseWorker(s, substr string) bool {
	// ç®€åŒ–ç‰ˆå¤§å°å†™ä¸æ•æ„Ÿæœç´¢
	for i := 0; i <= len(s)-len(substr); i++ {
		match := true
		for j := 0; j < len(substr); j++ {
			c1 := s[i+j]
			c2 := substr[j]
			if c1 >= 'A' && c1 <= 'Z' {
				c1 += 32
			}
			if c2 >= 'A' && c2 <= 'Z' {
				c2 += 32
			}
			if c1 != c2 {
				match = false
				break
			}
		}
		if match {
			return true
		}
	}
	return false
}

// newFileService åˆ›å»ºæ–‡ä»¶å­˜å‚¨æœåŠ¡
func newFileService(repo *repository.Repositories, cfg *config.Config) *file.Service {
	// é»˜è®¤ä½¿ç”¨æœ¬åœ°å­˜å‚¨
	storageType := file.StorageTypeLocal
	fileCfg := make(map[string]string)

	// ä»é…ç½®ä¸­è¯»å–æ–‡ä»¶å­˜å‚¨é…ç½®
	if cfg.File != nil {
		switch cfg.File.Type {
		case "minio":
			storageType = file.StorageTypeMinIO
			fileCfg = map[string]string{
				"endpoint":   cfg.File.MinIO.Endpoint,
				"access_key": cfg.File.MinIO.AccessKey,
				"secret_key": cfg.File.MinIO.SecretKey,
				"bucket":     cfg.File.MinIO.Bucket,
				"use_ssl":    cfg.File.MinIO.UseSSL,
				"url_prefix": cfg.File.MinIO.URLPrefix,
			}
		case "local":
			storageType = file.StorageTypeLocal
			fileCfg = map[string]string{
				"base_path":  cfg.File.Local.BasePath,
				"url_prefix": cfg.File.Local.URLPrefix,
			}
		}
	}

	// ä½¿ç”¨é»˜è®¤æœ¬åœ°é…ç½®
	if len(fileCfg) == 0 {
		fileCfg = map[string]string{
			"base_path":  "./data/files",
			"url_prefix": "/files",
		}
	}

	fileSvc, err := file.NewServiceFromConfig(repo, storageType, fileCfg)
	if err != nil {
		log.Printf("Warning: failed to create file service: %v, using nil", err)
		return nil
	}

	log.Printf("File service initialized with type: %s", storageType)
	return fileSvc
}
